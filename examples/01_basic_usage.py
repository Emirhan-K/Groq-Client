#!/usr/bin/env python3
"""
Temel KullanÄ±m Ã–rnekleri
========================

Bu dosya Groq Client'Ä±n temel Ã¶zelliklerini gÃ¶sterir:
- Ä°stemci oluÅŸturma
- Text generation
- Speech-to-text
- Context manager kullanÄ±mÄ±
"""

import os
import sys
import time

# Proje kÃ¶k dizinini Python path'ine ekle
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from client.groq_client import GroqClient

def basic_text_generation():
    """Temel text generation Ã¶rnekleri"""
    print("=" * 60)
    print("ğŸ“ TEMEL TEXT GENERATION")
    print("=" * 60)
    
    # API key'i ayarla
    api_key = "your_api_key"
    
    # Ä°stemci oluÅŸtur
    client = GroqClient(api_key)
    
    try:
        # 1. Basit prompt ile text generation
        print("\n1ï¸âƒ£ Basit Prompt ile Text Generation:")
        response = client.text.generate(
            model="llama3-8b-8192",
            prompt="Merhaba! Sen bir yardÄ±mcÄ± AI'sÄ±n. Kendini kÄ±saca tanÄ±tÄ±r mÄ±sÄ±n? LÃ¼tfen sadece TÃ¼rkÃ§e yanÄ±t ver.",
            max_tokens=150,
            temperature=0.7
        )
        print(f"Model: {response['model']}")
        print(f"KullanÄ±lan Token: {response['usage']['total_tokens']}")
        print(f"YanÄ±t: {response['choices'][0]['message']['content']}")
        
        # 2. Messages formatÄ± ile chat
        print("\n2ï¸âƒ£ Messages FormatÄ± ile Chat:")
        messages = [
            {"role": "system", "content": "Sen TÃ¼rkÃ§e konuÅŸan yardÄ±mcÄ± bir AI'sÄ±n. Sadece TÃ¼rkÃ§e yanÄ±t ver."},
            {"role": "user", "content": "Python'da liste ve tuple arasÄ±ndaki farkÄ± aÃ§Ä±kla."}
        ]
        
        response = client.text.generate(
            model="llama3-8b-8192",
            messages=messages,
            max_tokens=200,
            temperature=0.5
        )
        print(f"YanÄ±t: {response['choices'][0]['message']['content']}")
        
        # 3. Uzun yanÄ±t Ã¶rneÄŸi
        print("\n3ï¸âƒ£ Uzun YanÄ±t Ã–rneÄŸi:")
        response = client.text.generate(
            model="llama3-8b-8192",
            prompt="TÃ¼rkiye'nin en gÃ¼zel 3 ÅŸehrini say ve her birini kÄ±saca aÃ§Ä±kla:",
            max_tokens=300
        )
        print(f"YanÄ±t: {response['choices'][0]['message']['content']}")
        
        # 4. FarklÄ± modeller ile deneme
        print("\n4ï¸âƒ£ FarklÄ± Modeller:")
        models_to_try = ["llama3-8b-8192"]  # Sadece Ã§alÄ±ÅŸan model
        
        for model in models_to_try:
            try:
                response = client.text.generate(
                    model=model,
                    prompt=f"'{model}' modeli ile kÄ±sa bir TÃ¼rkÃ§e ÅŸiir yaz:",
                    max_tokens=100,
                    temperature=0.8
                )
                print(f"\n{model}:")
                print(response['choices'][0]['message']['content'])
            except Exception as e:
                print(f"{model}: Hata - {e}")
        
    except Exception as e:
        print(f"âŒ Hata: {e}")
    finally:
        # Ä°stemciyi kapat
        client.close()

def basic_speech_to_text():
    """Temel speech-to-text Ã¶rnekleri"""
    print("\n" + "=" * 60)
    print("ğŸ¤ TEMEL SPEECH-TO-TEXT")
    print("=" * 60)
    
    api_key = "your_api_key"
    client = GroqClient(api_key)
    
    try:
        # Ses dosyasÄ± yolu
        audio_file = "data/audio.mp3"
        
        if not os.path.exists(audio_file):
            print(f"âš ï¸ Ses dosyasÄ± bulunamadÄ±: {audio_file}")
            print("Ses dosyasÄ± olmadan STT testi yapÄ±lamÄ±yor.")
            return
        
        print(f"\n1ï¸âƒ£ Temel Transkripsiyon:")
        print(f"Ses dosyasÄ±: {audio_file}")
        
        # Temel transkripsiyon - Hata dÃ¼zeltmesi
        try:
            response = client.speech.transcribe(
                file=audio_file,
                model="whisper-large-v3"
            )
            print(f"Transkripsiyon: {response['text']}")
        except Exception as e:
            print(f"âš ï¸ STT hatasÄ±: {e}")
            print("STT testi atlanÄ±yor...")
            return
        
        # 2. Prompt ile transkripsiyon
        print("\n2ï¸âƒ£ Prompt ile Transkripsiyon:")
        try:
            response = client.speech.transcribe(
                file=audio_file,
                model="whisper-large-v3",
                prompt="Bu ses dosyasÄ± TÃ¼rkÃ§e konuÅŸma iÃ§eriyor."
            )
            print(f"Prompt ile transkripsiyon: {response['text']}")
        except Exception as e:
            print(f"Prompt ile transkripsiyon hatasÄ±: {e}")
        
        # 3. Dil belirtme
        print("\n3ï¸âƒ£ Dil Belirtme:")
        try:
            response = client.speech.transcribe(
                file=audio_file,
                model="whisper-large-v3",
                language="tr"
            )
            print(f"Dil belirtilerek transkripsiyon: {response['text']}")
        except Exception as e:
            print(f"Dil belirtme hatasÄ±: {e}")
        
        # 4. FarklÄ± STT modelleri
        print("\n4ï¸âƒ£ FarklÄ± STT Modelleri:")
        stt_models = ["whisper-large-v3", "whisper-large-v2"]
        
        for model in stt_models:
            try:
                response = client.speech.transcribe(
                    file=audio_file,
                    model=model
                )
                print(f"\n{model}:")
                print(f"Transkripsiyon: {response['text']}")
            except Exception as e:
                print(f"{model}: Hata - {e}")
        
    except Exception as e:
        print(f"âŒ STT HatasÄ±: {e}")
    finally:
        client.close()

def context_manager_usage():
    """Context manager kullanÄ±m Ã¶rnekleri"""
    print("\n" + "=" * 60)
    print("ğŸ”§ CONTEXT MANAGER KULLANIMI")
    print("=" * 60)
    
    api_key = "your_api_key"
    
    # Context manager ile kullanÄ±m
    with GroqClient(api_key) as client:
        try:
            print("\n1ï¸âƒ£ Context Manager ile Text Generation:")
            response = client.text.generate(
                model="llama3-8b-8192",
                prompt="Context manager kullanÄ±mÄ±nÄ±n avantajlarÄ±nÄ± aÃ§Ä±kla. Sadece TÃ¼rkÃ§e yanÄ±t ver:",
                max_tokens=150
            )
            print(response['choices'][0]['message']['content'])
            
            print("\n2ï¸âƒ£ Context Manager ile Birden Fazla Ä°stek:")
            
            # Birden fazla istek
            prompts = [
                "Python nedir? Sadece TÃ¼rkÃ§e aÃ§Ä±kla.",
                "JavaScript nedir? Sadece TÃ¼rkÃ§e aÃ§Ä±kla.",
                "Machine Learning nedir? Sadece TÃ¼rkÃ§e aÃ§Ä±kla."
            ]
            
            for i, prompt in enumerate(prompts, 1):
                response = client.text.generate(
                    model="llama3-8b-8192",
                    prompt=prompt,
                    max_tokens=100
                )
                print(f"\n{i}. {prompt}")
                print(f"YanÄ±t: {response['choices'][0]['message']['content'][:100]}...")
            
            print("\nâœ… Context manager otomatik olarak kaynaklarÄ± temizledi!")
            
        except Exception as e:
            print(f"âŒ Context Manager HatasÄ±: {e}")

def error_handling_examples():
    """Hata yÃ¶netimi Ã¶rnekleri"""
    print("\n" + "=" * 60)
    print("ğŸš¨ HATA YÃ–NETÄ°MÄ° Ã–RNEKLERÄ°")
    print("=" * 60)
    
    api_key = "your_api_key"
    client = GroqClient(api_key)
    
    try:
        # 1. GeÃ§ersiz model hatasÄ±
        print("\n1ï¸âƒ£ GeÃ§ersiz Model HatasÄ±:")
        try:
            response = client.text.generate(
                model="gecersiz-model",
                prompt="Test",
                max_tokens=10
            )
        except Exception as e:
            print(f"Beklenen hata: {type(e).__name__} - {e}")
        
        # 2. GeÃ§ersiz dosya hatasÄ±
        print("\n2ï¸âƒ£ GeÃ§ersiz Dosya HatasÄ±:")
        try:
            response = client.speech.transcribe(
                file="olmayan-dosya.mp3",
                model="whisper-large-v3"
            )
        except Exception as e:
            print(f"Beklenen hata: {type(e).__name__} - {e}")
        
        # 3. GeÃ§ersiz parametre hatasÄ±
        print("\n3ï¸âƒ£ GeÃ§ersiz Parametre HatasÄ±:")
        try:
            response = client.text.generate(
                model="llama3-8b-8192",
                prompt="",  # BoÅŸ prompt
                max_tokens=10
            )
        except Exception as e:
            print(f"Beklenen hata: {type(e).__name__} - {e}")
        
    except Exception as e:
        print(f"âŒ Genel Hata: {e}")
    finally:
        client.close()

def main():
    """Ana fonksiyon"""
    print("ğŸš€ GROQ CLIENT - TEMEL KULLANIM Ã–RNEKLERÄ°")
    print("=" * 60)
    
    # Temel Ã¶rnekler
    basic_text_generation()
    basic_speech_to_text()
    context_manager_usage()
    error_handling_examples()
    
    print("\n" + "=" * 60)
    print("âœ… TEMEL KULLANIM Ã–RNEKLERÄ° TAMAMLANDI")
    print("=" * 60)

if __name__ == "__main__":
    main() 